import time
import logging
from fastapi import FastAPI
from pydantic import BaseModel

from gaya_db_tool import TOOL_FUNCTIONS, TOOL_SCHEMA
from gaya_llm_router import processar_com_llm


# =====================================================
# CONFIGURA√á√ÉO DE LOG
# =====================================================

logger = logging.getLogger("GAYA_API")
logger.setLevel(logging.DEBUG)

handler = logging.StreamHandler()
handler.setFormatter(logging.Formatter("%(asctime)s - GAYA_API - %(levelname)s: %(message)s"))
logger.addHandler(handler)


# =====================================================
# FASTAPI APP
# =====================================================

app = FastAPI(title="Gaya AI API")


class Mensagem(BaseModel):
    text: str
    username: str
    user_id: int


# =====================================================
# ENDPOINT PRINCIPAL /mensagem
# =====================================================

@app.post("/mensagem")
async def receber_mensagem(msg: Mensagem):
    logger.info(f"üì• Mensagem recebida de {msg.username}: {msg.text}")
    time.sleep(1)

    # -------------------------------------------------------------------------
    # 1) CHAMADA AO MODELO PARA INTERPRETA√á√ÉO
    # -------------------------------------------------------------------------

    logger.info("üß† Enviando para LLM interpretar...")
    time.sleep(1)

    llm_result = processar_com_llm(
        pergunta=msg.text,
        ferramentas=[TOOL_SCHEMA]   # lista de tools dispon√≠veis
    )

    logger.debug(f"üîç Resposta inicial da LLM: {llm_result}")
    time.sleep(1)

    # -------------------------------------------------------------------------
    # 2) SE A LLM SOLICITAR UMA TOOL
    # -------------------------------------------------------------------------

    tool_solicitada = llm_result.get("usar_tool")

    if tool_solicitada:
        logger.warning(f"‚öôÔ∏è A LLM pediu a tool: {tool_solicitada}")
        time.sleep(1)

        # Tool existe?
        if tool_solicitada in TOOL_FUNCTIONS:

            logger.info(f"üöÄ Executando ferramenta '{tool_solicitada}'...")
            time.sleep(1)

            resultado_tool = TOOL_FUNCTIONS[tool_solicitada]()
            logger.info(f"üìä Retorno da ferramenta: {resultado_tool}")
            time.sleep(1)

            # ---------------------------------------------------------------
            # 3) GERA A RESPOSTA FINAL BASEADA NOS DADOS DO BANCO
            # ---------------------------------------------------------------

            logger.info("üß† Pedindo para a LLM montar a resposta final...")
            time.sleep(1)

            resposta_final = processar_com_llm(
                pergunta=f"Use estes dados e gere uma resposta natural, clara e √∫til: {resultado_tool}",
                ferramentas=[]   # agora n√£o pode chamar ferramentas
            )

            resposta_texto = resposta_final.get("resposta")
            logger.info(f"üí¨ Resposta final enviada: {resposta_texto}")

            return {"response": resposta_texto}

        else:
            logger.error(f"‚ùå Tool inexistente solicitada: {tool_solicitada}")
            return {"response": "Erro: a IA pediu uma ferramenta inexistente."}

    # -------------------------------------------------------------------------
    # 3) SE N√ÉO PEDIU TOOL ‚Üí RESPOSTA DIRETA
    # -------------------------------------------------------------------------

    logger.info("üí¨ A LLM respondeu diretamente.")
    time.sleep(1)

    return {"response": llm_result.get("resposta")}
